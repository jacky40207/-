{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"kerasbert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"182Q1YquVRy2Lm0HW1rQUvNKmuQzE1eVn","authorship_tag":"ABX9TyPVN1c4hjqeipGo8HOrnPDX"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"6Y83mx_L9TPL"},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","import pandas as pd\r\n","import re\r\n","import unicodedata\r\n","import nltk\r\n","from nltk.corpus import stopwords\r\n","from tqdm import tqdm\r\n","import pickle\r\n","from sklearn.metrics import confusion_matrix,f1_score,classification_report\r\n","import matplotlib.pyplot as plt\r\n","import itertools\r\n","from sklearn.utils import shuffle\r\n","!pip -q install keras_bert"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ztMZuc--1k3"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","dftrain=pd.read_csv('/content/drive/MyDrive/scibertfile/trainset_n.csv')\r\n","dftest=pd.read_csv('/content/drive/MyDrive/scibertfile/testset.csv')\r\n","dfval=pd.read_csv('/content/drive/MyDrive/scibertfile/validset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sGJhyJ_1Bvv","executionInfo":{"status":"ok","timestamp":1610955093846,"user_tz":-480,"elapsed":24791,"user":{"displayName":"洪瑞昕","photoUrl":"","userId":"07420144089275103813"}}},"source":["from keras_bert import load_trained_model_from_checkpoint, Tokenizer, get_custom_objects\r\n","from keras.layers import *\r\n","from keras.layers import Input\r\n","from keras.callbacks import *\r\n","from keras.models import Model, load_model\r\n","import keras.backend as K\r\n","from keras.optimizers import Adam\r\n","from keras.utils import to_categorical\r\n","import os\r\n","import keras\r\n","SEQ_LEN = 256\r\n","config_path = '/content/drive/MyDrive/scibertfile/Scibert/bert_config.json'\r\n","checkpoint_path = '/content/drive/MyDrive/scibertfile/Scibert/bert_model.ckpt'\r\n","vocab_path = '/content/drive/MyDrive/scibertfile/Scibert/vocab.txt'\r\n","\r\n","token_dict = {}\r\n","import codecs, gc, re\r\n","with codecs.open(vocab_path, 'r', 'utf8') as reader :\r\n","    for line in reader :\r\n","        token = line.strip()\r\n","        token_dict[token] = len(token_dict)\r\n","tokenizer = Tokenizer(token_dict)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"yi7-FXOSCwXa"},"source":["def unicode_to_ascii(s):\r\n","    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\r\n","nltk.download('stopwords')\r\n","def clean_stopwords_shortwords(w):\r\n","    stopwords_list=stopwords.words('english')\r\n","    words = w.split() \r\n","    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\r\n","    return \" \".join(clean_words) \r\n","def preprocess_sentence(w):\r\n","    w = unicode_to_ascii(w.lower().strip())\r\n","    w = re.sub(r\"([?.!,¿])\", r\" \", w)\r\n","    w = re.sub(r'[\" \"]+', \" \", w)\r\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\r\n","    w=clean_stopwords_shortwords(w)\r\n","    w=re.sub(r'@\\w+', '',w)\r\n","    return w\r\n","def label_to_onehot(labels) :\r\n","    \"\"\" Convert label to onehot .\r\n","        Args:\r\n","            labels (string): sentence's labels.\r\n","        Return:\r\n","            outputs (onehot list): sentence's onehot label.\r\n","    \"\"\"\r\n","    label_dict = {'THEORETICAL': 0, 'ENGINEERING':1, 'EMPIRICAL':2, 'OTHERS':3}\r\n","    onehot = [0,0,0,0]\r\n","    for l in labels.split():\r\n","        onehot[label_dict[l]] = 1\r\n","    return onehot\r\n","###Preprocess data###\r\n","def process_data(data, test=0) :\r\n","    all_x1 = []\r\n","    all_x2 = []\r\n","    label = []\r\n","    for i in range(len(data)) :\r\n","        sentid = []\r\n","        senti = []\r\n","        for sent in data['Abstract'][i]:\r\n","            x1, x2 = tokenizer.encode(sent)\r\n","            sentid = sentid + x1\r\n","            senti = senti + x2\r\n","        if test == 0:\r\n","            label.append(label_to_onehot(data['Classifications'][i]))\r\n","        if len(sentid) > SEQ_LEN :\r\n","            all_x1.append(sentid[-int(SEQ_LEN/2):] + sentid[:int(SEQ_LEN/2)])\r\n","            all_x2.append(senti[-int(SEQ_LEN/2):]+senti[:int(SEQ_LEN/2)])\r\n","        else :\r\n","            all_x1.append(sentid + [0] * (SEQ_LEN - len(sentid)))\r\n","            all_x2.append(senti + [0] * (SEQ_LEN - len(sentid)))\r\n","    if test == 0:\r\n","        return [np.asarray(all_x1), np.asarray(all_x2)], label\r\n","    else:\r\n","        return [np.asarray(all_x1), np.asarray(all_x2)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-bKwYSL2oB-"},"source":["dftrain_c=dftrain.copy()\r\n","dftrain_c['Abstract']=dftrain_c['Abstract'].map(preprocess_sentence)\r\n","x_train, y_train = process_data(dftrain_c)\r\n","\r\n","dfval_c=dfval.copy()\r\n","dfval_c['Abstract']=dfval_c['Abstract'].map(preprocess_sentence)\r\n","x_val, y_val = process_data(dfval_c)\r\n","\r\n","dftest_c=dftest.copy()\r\n","dftest_c['Abstract']=dftest_c['Abstract'].map(preprocess_sentence)\r\n","\r\n","dftest_c = process_data(dftest_c, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-0l0mQlkgUZ"},"source":["x_train = np.asarray(x_train)\r\n","y_train = np.asarray(y_train)\r\n","x_val = np.asarray(x_val)\r\n","y_val = np.asarray(y_val)\r\n","dftest_c = np.asarray(dftest_c)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcjULIQHgtnw"},"source":["class IntervalEvaluation(Callback):\r\n","    def __init__(self, validation_data=(), interval=10):\r\n","        super(Callback, self).__init__()\r\n","        self.interval = interval\r\n","        self.X_val, self.y_val = validation_data\r\n","    def on_epoch_end(self, epoch, logs={}):\r\n","        #if epoch % self.interval == 0:\r\n","        y_pred = (np.asarray(self.model.predict([self.X_val[0], self.X_val[1]]))).round().astype(int)\r\n","        score = f1_score(self.y_val, y_pred, average='micro')\r\n","        print(\"f1_score - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\r\n","get_f1 = IntervalEvaluation(validation_data=(x_val, y_val)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7iwt8WIpOxU"},"source":["bert_model = load_trained_model_from_checkpoint(\r\n","        config_path,\r\n","        checkpoint_path,\r\n","        training=True,\r\n","        trainable=True,\r\n","        seq_len=SEQ_LEN,\r\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQi7345f30t6","executionInfo":{"status":"ok","timestamp":1610702878696,"user_tz":-480,"elapsed":598612,"user":{"displayName":"洪瑞昕","photoUrl":"","userId":"07420144089275103813"}},"outputId":"2f161b90-c463-41c6-b59b-3b3afca701d3"},"source":["keras.backend.clear_session()\r\n","\r\n","inputs = bert_model.inputs[:2]\r\n","\r\n","frontout = bert_model.get_layer('Encoder-4-FeedForward-Norm').output\r\n","dense1 = GlobalAveragePooling1D()(frontout)\r\n","\r\n","modelout = bert_model.get_layer('Encoder-12-FeedForward-Norm').output\r\n","dense2 = GlobalAveragePooling1D()(modelout)\r\n","\r\n","denseout = keras.layers.Maximum()([dense2, dense1])\r\n","\r\n","denseout = Dropout(0.1)(denseout)\r\n","\r\n","outputs = Dense(4, activation='sigmoid')(denseout)\r\n","\r\n","model = Model(inputs, outputs)\r\n","\r\n","print(model.summary())\r\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-5), metrics=['binary_accuracy'])\r\n","es = EarlyStopping(monitor='val_binary_accuracy', mode='auto', verbose=1, patience=2, restore_best_weights=True)\r\n","mc = ModelCheckpoint(filepath='/content/drive/MyDrive/scibertfile/bert_model.h5', save_best_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      [(None, 256)]        0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (TokenEmbedding [(None, 256, 768), ( 23877120    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, 256, 768)     1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, 256, 768)     0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, 256, 768)     196608      Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, 256, 768)     0           Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, 256, 768)     1536        Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Embedding-Norm[0][0]             \n","                                                                 Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-1-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention-\n","                                                                 Encoder-1-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n","                                                                 Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-2-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention-\n","                                                                 Encoder-2-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n","                                                                 Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-3-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention-\n","                                                                 Encoder-3-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n","                                                                 Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-4-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention-\n","                                                                 Encoder-4-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n","                                                                 Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-5-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention-\n","                                                                 Encoder-5-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n","                                                                 Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-6-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention-\n","                                                                 Encoder-6-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n","                                                                 Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-7-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention-\n","                                                                 Encoder-7-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n","                                                                 Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-8-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention-\n","                                                                 Encoder-8-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n","                                                                 Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-9-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention-\n","                                                                 Encoder-9-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n","                                                                 Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Dropout  (None, 256, 768)     0           Encoder-10-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Add (Add (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n","                                                                 Encoder-10-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n","                                                                 Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Dropout  (None, 256, 768)     0           Encoder-11-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Add (Add (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n","                                                                 Encoder-11-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n","                                                                 Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Dropout  (None, 256, 768)     0           Encoder-12-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Add (Add (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n","                                                                 Encoder-12-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","global_average_pooling1d (Globa (None, 768)          0           Encoder-4-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","maximum (Maximum)               (None, 768)          0           global_average_pooling1d_1[0][0] \n","                                                                 global_average_pooling1d[0][0]   \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 768)          0           maximum[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 4)            3076        dropout[0][0]                    \n","==================================================================================================\n","Total params: 109,134,340\n","Trainable params: 109,134,340\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y0ctyBgA38vq"},"source":["history = model.fit([x_train[0], x_train[1]]\r\n","                    , y_train, batch_size=4\r\n","                    , epochs=10, validation_data=([x_val[0], x_val[1]],y_val)\r\n","                    , callbacks=[get_f1,es,mc])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UR3oscdflI8I","executionInfo":{"status":"ok","timestamp":1610955252325,"user_tz":-480,"elapsed":32169,"user":{"displayName":"洪瑞昕","photoUrl":"","userId":"07420144089275103813"}}},"source":["model = load_model('/content/drive/MyDrive/scibertfile/bert_model_1.h5', custom_objects=get_custom_objects())"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpeiYbDklJD3"},"source":["ans_pred = model.predict([dftest_c[0], dftest_c[1]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMNPd3BzuDmi"},"source":["valpred = model.predict([x_val[0], x_val[1]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6DKD8xplTeR"},"source":["###Function to modify the threshold of sigmoid output###\r\n","def mod_round(data, threshold=0.5):\r\n","    pred = []\r\n","    for i in range(len(data)) :\r\n","        pred_line = []\r\n","        for j in range(4) :\r\n","            if(data[i][j]) > threshold :\r\n","                pred_line += [1]\r\n","            else :\r\n","                pred_line += [0]\r\n","        pred.append(pred_line)\r\n","    pred = np.asarray(pred).astype(int)\r\n","    return pred\r\n","\r\n","###Fix the unreasonable prediction###\r\n","def fix_ans(data):\r\n","    wrong1 = 0\r\n","    wrong2 = 0\r\n","    others = 0\r\n","    for i in range(len(data)):\r\n","        if sum(data[i]) == 0:\r\n","            wrong1 += 1\r\n","            data[i] = [0,0,0,1]\r\n","        if sum(data[i][0:3]) > 0 and data[i][3] == 1:\r\n","            wrong2 += 1\r\n","            data[i][3] = 0\r\n","        if data[i][3] == 1 :\r\n","            others += 1\r\n","    return data, wrong1, wrong2, others\r\n","\r\n","###Calculate the F1-score when testing with validation data###\r\n","def cal_score(data, y_val) :\r\n","    TP = 0\r\n","    AP = 0\r\n","    TL = 0\r\n","    for i in range(len(data)) :\r\n","        TP = TP + (data[i]*y_val[i]).sum()\r\n","        AP = AP + (data[i].sum())\r\n","        TL = TL + (y_val[i]).sum()\r\n","    precision = TP / AP\r\n","    recall = TP / TL\r\n","    FS = 2*precision*recall/(precision+recall)\r\n","    #print(TP, AP, TL)\r\n","    return precision, recall, FS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGLggPoMlWKZ"},"source":["pred = mod_round(ans_pred,0.419)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"REecsLIUJY1F"},"source":["pred_v = mod_round(valpred,0)\r\n","oprecision, orecall, oFS=cal_score(pred_v, y_val)\r\n","j=0\r\n","for i in np.arange(0, 0.7, .001):\r\n","    precision, recall, FS=cal_score(mod_round(valpred,i), y_val)\r\n","    if FS>oFS:\r\n","        oFS=FS\r\n","        oprecision=precision\r\n","        orecall=recall\r\n","        j=i\r\n","print(j,oprecision, orecall, oFS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"rR5T6oZlJWyG","executionInfo":{"elapsed":723426,"status":"ok","timestamp":1610609349861,"user":{"displayName":"洪瑞昕","photoUrl":"","userId":"07420144089275103813"},"user_tz":-480},"outputId":"8555f498-1ddc-407f-ce26-301da499b24e"},"source":["y_val"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.591715976331361"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FL7s8MXezj17","executionInfo":{"elapsed":687,"status":"ok","timestamp":1610609545093,"user":{"displayName":"洪瑞昕","photoUrl":"","userId":"07420144089275103813"},"user_tz":-480},"outputId":"4921e55a-060c-492b-d1f9-fa8f01e66361"},"source":["z=valpred*y_val\r\n","z"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.48903233, 0.        , 0.        ],\n","       [0.6578359 , 0.        , 0.        , 0.        ],\n","       [0.5846656 , 0.52058625, 0.        , 0.        ],\n","       ...,\n","       [0.        , 0.        , 0.22016521, 0.        ],\n","       [0.        , 0.        , 0.33821541, 0.        ],\n","       [0.4888925 , 0.        , 0.        , 0.        ]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QLB9kpzlb8H","executionInfo":{"elapsed":3267,"status":"ok","timestamp":1610609724940,"user":{"displayName":"洪瑞昕","photoUrl":"","userId":"07420144089275103813"},"user_tz":-480},"outputId":"0a337ca2-25c7-441b-e4ae-4d2e85f593c7"},"source":["pred, wrong1, wrong2, others = fix_ans(pred)\r\n","print(pred, wrong1, wrong2, others)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0 1 0 0]\n"," [0 1 0 0]\n"," [1 1 0 0]\n"," ...\n"," [1 1 0 0]\n"," [1 1 0 0]\n"," [1 1 0 0]] 0 0 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GyDjDqAllb-z"},"source":["###Fix the outlier of test data###\r\n","for index in outlier : \r\n","    pred[index] = [0,0,0,1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YQN-DST1DOJ","executionInfo":{"elapsed":783,"status":"ok","timestamp":1610609868968,"user":{"displayName":"洪瑞昕","photoUrl":"","userId":"07420144089275103813"},"user_tz":-480},"outputId":"08880052-0b11-4450-c660-533fcf01e8e7"},"source":["pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 1, 0, 0],\n","       ...,\n","       [1, 1, 0, 0],\n","       [1, 1, 0, 0],\n","       [1, 1, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"iqhCuExOlcB7","outputId":"361d4e53-047f-4c11-dfc6-c46a3ce139e9"},"source":["###To calculate f1-score of validation dataset###\r\n","print(cal_score(pred_v, y_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0.47832817337461303, 0.6746724890829694, 0.5597826086956521)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KZi3aoD1lfLX"},"source":["###List the f1-score with different threshold on validation data###\r\n","table = []\r\n","for i in range(400,500,1) :\r\n","    pred = mod_round(val1pred, i/1000)\r\n","    pred, wrong1, wrong2, others = fix_ans(pred)\r\n","    recision, recall, FS = cal_score(pred, y_val)\r\n","    table.append([i/1000, recision, recall, FS])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbkzgwN3lhGf"},"source":["def SubmitGenerator(prediction, sampleFile, public=True, filename='prediction.csv'):\r\n","    \"\"\"\r\n","    Args:\r\n","        prediction (numpy array)\r\n","        sampleFile (str)\r\n","        public (boolean)\r\n","        filename (str)\r\n","    \"\"\"\r\n","    sample = pd.read_csv(sampleFile)\r\n","    submit = {}\r\n","    submit['order_id'] = list(sample.order_id.values)\r\n","    redundant = len(sample) - prediction.shape[0]\r\n","    if public:\r\n","        submit['THEORETICAL'] = list(prediction[:,0]) + [0]*redundant\r\n","        submit['ENGINEERING'] = list(prediction[:,1]) + [0]*redundant\r\n","        submit['EMPIRICAL'] = list(prediction[:,2]) + [0]*redundant\r\n","        submit['OTHERS'] = list(prediction[:,3]) + [0]*redundant\r\n","    else:\r\n","        submit['THEORETICAL'] = [0]*redundant + list(prediction[:,0])\r\n","        submit['ENGINEERING'] = [0]*redundant + list(prediction[:,1])\r\n","        submit['EMPIRICAL'] = [0]*redundant + list(prediction[:,2])\r\n","        submit['OTHERS'] = [0]*redundant + list(prediction[:,3])\r\n","    df = pd.DataFrame.from_dict(submit) \r\n","    df.to_csv(filename,index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDfj2c8Clo1w"},"source":["CWD = os.getcwd()\r\n","SubmitGenerator(pred, \r\n","                os.path.join(CWD,'data/task2_sample_submission.csv'),\r\n","                False, \r\n","                os.path.join(CWD,'task2_submission_0102.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7J7Dbq8yw5i"},"source":[""],"execution_count":null,"outputs":[]}]}