{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "kerasbert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y83mx_L9TPL"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import unicodedata\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from tqdm import tqdm\r\n",
        "import pickle\r\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import itertools\r\n",
        "from sklearn.utils import shuffle\r\n",
        "!pip -q install keras_bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ztMZuc--1k3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "dftrain=pd.read_csv('/content/drive/MyDrive/scibertfile/trainset_n.csv')\r\n",
        "dftest=pd.read_csv('/content/drive/MyDrive/scibertfile/testset.csv')\r\n",
        "dfval=pd.read_csv('/content/drive/MyDrive/scibertfile/validset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sGJhyJ_1Bvv"
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint, Tokenizer, get_custom_objects\r\n",
        "from keras.layers import *\r\n",
        "from keras.layers import Input\r\n",
        "from keras.callbacks import *\r\n",
        "from keras.models import Model, load_model\r\n",
        "import keras.backend as K\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.utils import to_categorical\r\n",
        "import os\r\n",
        "import keras\r\n",
        "SEQ_LEN = 256\r\n",
        "config_path = '/content/drive/MyDrive/scibertfile/Scibert/bert_config.json'\r\n",
        "checkpoint_path = '/content/drive/MyDrive/scibertfile/Scibert/bert_model.ckpt'\r\n",
        "vocab_path = '/content/drive/MyDrive/scibertfile/Scibert/vocab.txt'\r\n",
        "\r\n",
        "token_dict = {}\r\n",
        "import codecs, gc, re\r\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader :\r\n",
        "    for line in reader :\r\n",
        "        token = line.strip()\r\n",
        "        token_dict[token] = len(token_dict)\r\n",
        "tokenizer = Tokenizer(token_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi7-FXOSCwXa"
      },
      "source": [
        "def unicode_to_ascii(s):\r\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\r\n",
        "nltk.download('stopwords')\r\n",
        "def clean_stopwords_shortwords(w):\r\n",
        "    stopwords_list=stopwords.words('english')\r\n",
        "    words = w.split() \r\n",
        "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\r\n",
        "    return \" \".join(clean_words) \r\n",
        "def preprocess_sentence(w):\r\n",
        "    w = unicode_to_ascii(w.lower().strip())\r\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\r\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\r\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\r\n",
        "    w=clean_stopwords_shortwords(w)\r\n",
        "    w=re.sub(r'@\\w+', '',w)\r\n",
        "    return w\r\n",
        "def label_to_onehot(labels) :\r\n",
        "    \"\"\" Convert label to onehot .\r\n",
        "        Args:\r\n",
        "            labels (string): sentence's labels.\r\n",
        "        Return:\r\n",
        "            outputs (onehot list): sentence's onehot label.\r\n",
        "    \"\"\"\r\n",
        "    label_dict = {'THEORETICAL': 0, 'ENGINEERING':1, 'EMPIRICAL':2, 'OTHERS':3}\r\n",
        "    onehot = [0,0,0,0]\r\n",
        "    for l in labels.split():\r\n",
        "        onehot[label_dict[l]] = 1\r\n",
        "    return onehot\r\n",
        "###Preprocess data###\r\n",
        "def process_data(data, test=0) :\r\n",
        "    all_x1 = []\r\n",
        "    all_x2 = []\r\n",
        "    label = []\r\n",
        "    for i in range(len(data)) :\r\n",
        "        sentid = []\r\n",
        "        senti = []\r\n",
        "        for sent in data['Abstract'][i]:\r\n",
        "            x1, x2 = tokenizer.encode(sent)\r\n",
        "            sentid = sentid + x1\r\n",
        "            senti = senti + x2\r\n",
        "        if test == 0:\r\n",
        "            label.append(label_to_onehot(data['Classifications'][i]))\r\n",
        "        if len(sentid) > SEQ_LEN :\r\n",
        "            all_x1.append(sentid[-int(SEQ_LEN/2):] + sentid[:int(SEQ_LEN/2)])\r\n",
        "            all_x2.append(senti[-int(SEQ_LEN/2):]+senti[:int(SEQ_LEN/2)])\r\n",
        "        else :\r\n",
        "            all_x1.append(sentid + [0] * (SEQ_LEN - len(sentid)))\r\n",
        "            all_x2.append(senti + [0] * (SEQ_LEN - len(sentid)))\r\n",
        "    if test == 0:\r\n",
        "        return [np.asarray(all_x1), np.asarray(all_x2)], label\r\n",
        "    else:\r\n",
        "        return [np.asarray(all_x1), np.asarray(all_x2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-bKwYSL2oB-"
      },
      "source": [
        "dftrain_c=dftrain.copy()\r\n",
        "dftrain_c['Abstract']=dftrain_c['Abstract'].map(preprocess_sentence)\r\n",
        "x_train, y_train = process_data(dftrain_c)\r\n",
        "\r\n",
        "dfval_c=dfval.copy()\r\n",
        "dfval_c['Abstract']=dfval_c['Abstract'].map(preprocess_sentence)\r\n",
        "x_val, y_val = process_data(dfval_c)\r\n",
        "\r\n",
        "dftest_c=dftest.copy()\r\n",
        "dftest_c['Abstract']=dftest_c['Abstract'].map(preprocess_sentence)\r\n",
        "\r\n",
        "dftest_c = process_data(dftest_c, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-0l0mQlkgUZ"
      },
      "source": [
        "x_train = np.asarray(x_train)\r\n",
        "y_train = np.asarray(y_train)\r\n",
        "x_val = np.asarray(x_val)\r\n",
        "y_val = np.asarray(y_val)\r\n",
        "dftest_c = np.asarray(dftest_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcjULIQHgtnw"
      },
      "source": [
        "class IntervalEvaluation(Callback):\r\n",
        "    def __init__(self, validation_data=(), interval=10):\r\n",
        "        super(Callback, self).__init__()\r\n",
        "        self.interval = interval\r\n",
        "        self.X_val, self.y_val = validation_data\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        #if epoch % self.interval == 0:\r\n",
        "        y_pred = (np.asarray(self.model.predict([self.X_val[0], self.X_val[1]]))).round().astype(int)\r\n",
        "        score = f1_score(self.y_val, y_pred, average='micro')\r\n",
        "        print(\"f1_score - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\r\n",
        "get_f1 = IntervalEvaluation(validation_data=(x_val, y_val)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7iwt8WIpOxU"
      },
      "source": [
        "bert_model = load_trained_model_from_checkpoint(\r\n",
        "        config_path,\r\n",
        "        checkpoint_path,\r\n",
        "        training=True,\r\n",
        "        trainable=True,\r\n",
        "        seq_len=SEQ_LEN,\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQi7345f30t6"
      },
      "source": [
        "keras.backend.clear_session()\r\n",
        "\r\n",
        "inputs = bert_model.inputs[:2]\r\n",
        "\r\n",
        "frontout = bert_model.get_layer('Encoder-4-FeedForward-Norm').output\r\n",
        "dense1 = GlobalAveragePooling1D()(frontout)\r\n",
        "\r\n",
        "modelout = bert_model.get_layer('Encoder-12-FeedForward-Norm').output\r\n",
        "dense2 = GlobalAveragePooling1D()(modelout)\r\n",
        "\r\n",
        "denseout = keras.layers.Maximum()([dense2, dense1])\r\n",
        "\r\n",
        "denseout = Dropout(0.1)(denseout)\r\n",
        "\r\n",
        "outputs = Dense(4, activation='sigmoid')(denseout)\r\n",
        "\r\n",
        "model = Model(inputs, outputs)\r\n",
        "\r\n",
        "print(model.summary())\r\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-5), metrics=['binary_accuracy'])\r\n",
        "es = EarlyStopping(monitor='val_binary_accuracy', mode='auto', verbose=1, patience=2, restore_best_weights=True)\r\n",
        "mc = ModelCheckpoint(filepath='/content/drive/MyDrive/scibertfile/bert_model_3.h5', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ctyBgA38vq"
      },
      "source": [
        "history = model.fit([x_train[0], x_train[1]]\r\n",
        "                    , y_train, batch_size=4\r\n",
        "                    , epochs=50, validation_data=([x_val[0], x_val[1]],y_val)\r\n",
        "                    , callbacks=[get_f1,es,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3oscdflI8I"
      },
      "source": [
        "model = load_model('/content/drive/MyDrive/scibertfile/bert_model_3.h5', custom_objects=get_custom_objects())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMNPd3BzuDmi"
      },
      "source": [
        "valpred = model.predict([x_val[0], x_val[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6DKD8xplTeR"
      },
      "source": [
        "###Function to modify the threshold of sigmoid output###\r\n",
        "def mod_round(data, threshold=0.5):\r\n",
        "    pred = []\r\n",
        "    for i in range(len(data)) :\r\n",
        "        pred_line = []\r\n",
        "        for j in range(4) :\r\n",
        "            if(data[i][j]) > threshold :\r\n",
        "                pred_line += [1]\r\n",
        "            else :\r\n",
        "                pred_line += [0]\r\n",
        "        pred.append(pred_line)\r\n",
        "    pred = np.asarray(pred).astype(int)\r\n",
        "    return pred\r\n",
        "\r\n",
        "###Fix the unreasonable prediction###\r\n",
        "def fix_ans(data):\r\n",
        "    wrong1 = 0\r\n",
        "    wrong2 = 0\r\n",
        "    others = 0\r\n",
        "    for i in range(len(data)):\r\n",
        "        if sum(data[i]) == 0:\r\n",
        "            wrong1 += 1\r\n",
        "            data[i] = [0,0,0,1]\r\n",
        "        if sum(data[i][0:3]) > 0 and data[i][3] == 1:\r\n",
        "            wrong2 += 1\r\n",
        "            data[i][3] = 0\r\n",
        "        if data[i][3] == 1 :\r\n",
        "            others += 1\r\n",
        "    return data, wrong1, wrong2, others\r\n",
        "\r\n",
        "###Calculate the F1-score when testing with validation data###\r\n",
        "def cal_score(data, y_val) :\r\n",
        "    TP = 0\r\n",
        "    AP = 0\r\n",
        "    TL = 0\r\n",
        "    for i in range(len(data)) :\r\n",
        "        TP = TP + (data[i]*y_val[i]).sum()\r\n",
        "        AP = AP + (data[i].sum())\r\n",
        "        TL = TL + (y_val[i]).sum()\r\n",
        "    precision = TP / AP\r\n",
        "    recall = TP / TL\r\n",
        "    FS = 2*precision*recall/(precision+recall)\r\n",
        "    #print(TP, AP, TL)\r\n",
        "    return precision, recall, FS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REecsLIUJY1F"
      },
      "source": [
        "pred_v = mod_round(valpred,0)\r\n",
        "oprecision, orecall, oFS=cal_score(pred_v, y_val)\r\n",
        "j=0\r\n",
        "for i in np.arange(0, 0.7, .001):\r\n",
        "    precision, recall, FS=cal_score(mod_round(valpred,i), y_val)\r\n",
        "    if FS>oFS:\r\n",
        "        oFS=FS\r\n",
        "        oprecision=precision\r\n",
        "        orecall=recall\r\n",
        "        j=i\r\n",
        "print(j,oprecision, orecall, oFS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbkzgwN3lhGf"
      },
      "source": [
        "def SubmitGenerator(prediction, sampleFile, public=True, filename='prediction.csv'):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "        prediction (numpy array)\r\n",
        "        sampleFile (str)\r\n",
        "        public (boolean)\r\n",
        "        filename (str)\r\n",
        "    \"\"\"\r\n",
        "    sample = pd.read_csv(sampleFile)\r\n",
        "    submit = {}\r\n",
        "    submit['order_id'] = list(sample.order_id.values)\r\n",
        "    redundant = len(sample) - prediction.shape[0]\r\n",
        "    if public:\r\n",
        "        submit['THEORETICAL'] = list(prediction[:,0]) + [0]*redundant\r\n",
        "        submit['ENGINEERING'] = list(prediction[:,1]) + [0]*redundant\r\n",
        "        submit['EMPIRICAL'] = list(prediction[:,2]) + [0]*redundant\r\n",
        "        submit['OTHERS'] = list(prediction[:,3]) + [0]*redundant\r\n",
        "    else:\r\n",
        "        submit['THEORETICAL'] = [0]*redundant + list(prediction[:,0])\r\n",
        "        submit['ENGINEERING'] = [0]*redundant + list(prediction[:,1])\r\n",
        "        submit['EMPIRICAL'] = [0]*redundant + list(prediction[:,2])\r\n",
        "        submit['OTHERS'] = [0]*redundant + list(prediction[:,3])\r\n",
        "    df = pd.DataFrame.from_dict(submit) \r\n",
        "    df.to_csv(filename,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDfj2c8Clo1w"
      },
      "source": [
        "CWD = os.getcwd()\r\n",
        "SubmitGenerator(pred, \r\n",
        "                os.path.join(CWD,'data/task2_sample_submission.csv'),\r\n",
        "                False, \r\n",
        "                os.path.join(CWD,'task2_submission_0102.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7J7Dbq8yw5i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}